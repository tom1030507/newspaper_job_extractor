"""
å ±ç´™å·¥ä½œå»£å‘Šå€å¡Šæå–ç³»çµ± - æ¨¡çµ„åŒ–é‡æ§‹ç‰ˆæœ¬
ä¸»æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
"""
import os
import threading
import time
import schedule
from datetime import datetime
from flask import Flask
from flask_socketio import SocketIO, emit

# å°å…¥é…ç½®
from config import Config, config

# å°å…¥æ¨¡å‹å’Œå­˜å„²
from models import image_storage, job_storage, progress_storage

# å°å…¥æœå‹™
from services import progress_tracker, ai_service, image_processing_service

# å°å…¥è·¯ç”±
from routes import main_bp, upload_bp, results_bp

# å°å…¥å·¥å…·å‡½æ•¸
from utils import cleanup_old_files, get_storage_info

def create_app(config_name='default'):
    """æ‡‰ç”¨ç¨‹å¼å·¥å» å‡½æ•¸"""
    app = Flask(__name__, static_folder='.', static_url_path='')
    
    # è¼‰å…¥é…ç½®
    app.config.from_object(config[config_name])
    config[config_name].init_app(app)
    
    # åˆå§‹åŒ– SocketIO
    socketio = SocketIO(app, cors_allowed_origins=Config.CORS_ALLOWED_ORIGINS)
    
    # è¨­ç½®é€²åº¦è¿½è¹¤å™¨çš„ SocketIO å¯¦ä¾‹
    progress_tracker.socketio = socketio
    
    # è¨»å†Šè—åœ–
    app.register_blueprint(main_bp)
    app.register_blueprint(upload_bp)
    app.register_blueprint(results_bp)
    
    # SocketIO äº‹ä»¶è™•ç†
    @socketio.on('connect')
    def handle_connect():
        """è™•ç†å®¢æˆ¶ç«¯é€£æ¥"""
        from flask import request
        print(f"å®¢æˆ¶ç«¯å·²é€£æ¥: {request.sid}")

    @socketio.on('disconnect')
    def handle_disconnect():
        """è™•ç†å®¢æˆ¶ç«¯æ–·é–‹é€£æ¥"""
        from flask import request
        print(f"å®¢æˆ¶ç«¯å·²æ–·é–‹: {request.sid}")

    @socketio.on('get_progress')
    def handle_get_progress(data):
        """è™•ç†å®¢æˆ¶ç«¯è«‹æ±‚é€²åº¦è³‡è¨Š"""
        process_id = data.get('process_id')
        progress_data = progress_tracker.get_progress(process_id)
        if progress_data:
            emit('progress_update', {
                'process_id': process_id,
                **progress_data
            })
    
    # ç®¡ç†è·¯ç”±
    @app.route('/admin/storage')
    def admin_storage():
        """ç®¡ç†å“¡æŸ¥çœ‹å­˜å„²ç‹€æ…‹"""
        from flask import jsonify
        
        storage_info = get_storage_info(Config.RESULTS_FOLDER)
        storage_info['memory_processes'] = len(image_storage._storage)
        
        # ç²å–æœ€è¿‘çš„è™•ç†è¨˜éŒ„
        recent_processes = []
        if os.path.exists(Config.RESULTS_FOLDER):
            for item in os.listdir(Config.RESULTS_FOLDER):
                item_path = os.path.join(Config.RESULTS_FOLDER, item)
                if os.path.isdir(item_path):
                    recent_processes.append({
                        'process_id': item,
                        'created_time': datetime.fromtimestamp(os.path.getctime(item_path)).isoformat(),
                        'size_mb': round(sum(os.path.getsize(os.path.join(root, file)) 
                                           for root, dirs, files in os.walk(item_path) 
                                           for file in files) / (1024 * 1024), 2)
                    })
        
        # æŒ‰å‰µå»ºæ™‚é–“æ’åº
        recent_processes.sort(key=lambda x: x['created_time'], reverse=True)
        
        return jsonify({
            'storage_info': storage_info,
            'recent_processes': recent_processes[:10],  # åªé¡¯ç¤ºæœ€è¿‘10å€‹
            'status': 'success'
        })

    @app.route('/admin/cleanup', methods=['POST'])
    def admin_cleanup():
        """æ‰‹å‹•æ¸…ç†èˆŠæª”æ¡ˆ"""
        from flask import request, jsonify
        
        try:
            max_age_hours = request.json.get('max_age_hours', Config.CLEANUP_MAX_AGE_HOURS) if request.json else Config.CLEANUP_MAX_AGE_HOURS
            cleanup_old_files(Config.UPLOAD_FOLDER, Config.RESULTS_FOLDER, max_age_hours)
            
            # ç²å–æ¸…ç†å¾Œçš„å­˜å„²è³‡è¨Š
            storage_info = get_storage_info(Config.RESULTS_FOLDER)
            storage_info['memory_processes'] = len(image_storage._storage)
            
            return jsonify({
                'message': f'å·²æ¸…ç†è¶…é {max_age_hours} å°æ™‚çš„æª”æ¡ˆ',
                'storage_info': storage_info,
                'status': 'success'
            })
        except Exception as e:
            return jsonify({
                'error': f'æ¸…ç†å¤±æ•—: {str(e)}',
                'status': 'error'
            }), 500

    @app.route('/admin/cleanup/auto', methods=['POST'])
    def toggle_auto_cleanup():
        """åˆ‡æ›è‡ªå‹•æ¸…ç†åŠŸèƒ½"""
        from flask import request, jsonify
        
        try:
            enabled = request.json.get('enabled', True) if request.json else True
            
            if enabled:
                start_cleanup_scheduler()
                message = f"è‡ªå‹•æ¸…ç†å·²å•Ÿç”¨ï¼Œæ¯{Config.CLEANUP_INTERVAL_HOURS}å°æ™‚åŸ·è¡Œä¸€æ¬¡"
            else:
                schedule.clear()
                message = "è‡ªå‹•æ¸…ç†å·²åœç”¨"
            
            return jsonify({
                'message': message,
                'auto_cleanup_enabled': enabled,
                'status': 'success'
            })
        except Exception as e:
            return jsonify({
                'error': f'åˆ‡æ›è‡ªå‹•æ¸…ç†å¤±æ•—: {str(e)}',
                'status': 'error'
            }), 500
    
    # Google Sheets æ•´åˆè·¯ç”±
    @app.route('/send_to_spreadsheet/<process_id>', methods=['POST'])
    def send_to_spreadsheet(process_id):
        """å°‡è™•ç†çµæœç™¼é€åˆ° Google Sheets"""
        from flask import request, jsonify
        from utils.file_utils import is_valid_job
        import requests
        
        try:
            # å¾è«‹æ±‚ä¸­ç²å– Google Apps Script URLï¼ˆç¾åœ¨è®Šç‚ºå¯é¸ï¼‰
            data = request.get_json() if request.get_json() else {}
            apps_script_url = data.get('apps_script_url', '')
            
            # å¦‚æœæ²’æœ‰æä¾› URLï¼Œä½¿ç”¨é»˜èªçš„è‡ªå‹•å‰µå»º Google Sheet çš„ Apps Script
            if not apps_script_url:
                # TODO: è«‹å°‡ä¸‹é¢çš„ URL æ›¿æ›ç‚ºæ‚¨å¯¦éš›éƒ¨ç½²çš„ Google Apps Script URL
                apps_script_url = 'YOUR_ACTUAL_GOOGLE_APPS_SCRIPT_URL_HERE'  # è«‹æ›¿æ›ç‚ºå¯¦éš›éƒ¨ç½²çš„ URL
                
                # å¦‚æœé‚„æ²’æœ‰è¨­ç½®çœŸå¯¦çš„ URLï¼Œè¿”å›éŒ¯èª¤
                if apps_script_url == 'YOUR_ACTUAL_GOOGLE_APPS_SCRIPT_URL_HERE':
                    return jsonify({
                        'error': 'è«‹å…ˆè¨­ç½® Google Apps Script URL',
                        'message': 'è«‹åƒè€ƒ GOOGLE_APPS_SCRIPT_SETUP.md æ–‡ä»¶ä¾†éƒ¨ç½²æ‚¨çš„ Google Apps Scriptï¼Œç„¶å¾Œæ›´æ–°ç¨‹å¼ä¸­çš„ URL'
                    }), 400
            
            # æ”¶é›†è·ç¼ºè³‡æ–™ - ä½¿ç”¨èˆ‡ results å’Œ download ç›¸åŒçš„é‚è¼¯
            all_jobs = []
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºPDFæˆ–å¤šæª”æ¡ˆ
            pdf_page_keys = [key for key in image_storage._storage.keys() if key.startswith(f"{process_id}_page")]
            multi_file_keys = [key for key in image_storage._storage.keys() if key.startswith(f"{process_id}_file")]
            
            if pdf_page_keys:
                # PDFæƒ…æ³
                pdf_page_keys.sort(key=lambda x: int(x.split('_page')[-1]))
                
                for page_key in pdf_page_keys:
                    page_num = page_key.split('_page')[-1]
                    
                    for filename, image_data in image_storage._storage[page_key].items():
                        # è·³éåµéŒ¯åœ–åƒ
                        if any(debug_type in filename for debug_type in ['_original', '_mask_', '_final_combined']):
                            continue
                        
                        # ç›´æ¥å¾ image_storage ç²å–æè¿°
                        description = []
                        if page_key in image_storage._storage and \
                           filename in image_storage._storage[page_key] and \
                           'description' in image_storage._storage[page_key][filename]:
                            description = image_storage._storage[page_key][filename]['description']
                        else:
                            print(f"è­¦å‘Š: åœ¨ send_to_spreadsheet ä¸­æ‰¾ä¸åˆ°åœ–ç‰‡ {filename} (page_key: {page_key}) çš„æè¿°ï¼Œå°‡ä½¿ç”¨ç©ºæè¿°ã€‚")
                            description = [{
                                "å·¥ä½œ": "æè¿°æœªæ‰¾åˆ°",
                                "è¡Œæ¥­": "", "æ™‚é–“": "", "è–ªè³‡": "",
                                "åœ°é»": "", "è¯çµ¡æ–¹å¼": "", "å…¶ä»–": ""
                            }]
                        
                        # æ”¶é›†æœ‰æ•ˆçš„å·¥ä½œè³‡è¨Š
                        if isinstance(description, list):
                            for i, job in enumerate(description):
                                if is_valid_job(job):
                                    job_info = job.copy()
                                    job_info['ä¾†æºåœ–ç‰‡'] = filename
                                    job_info['é ç¢¼'] = page_num
                                    job_info['åœ–ç‰‡ç·¨è™Ÿ'] = f"page{page_num}_{filename.split('.')[0]}"
                                    if len([j for j in description if is_valid_job(j)]) > 1:
                                        valid_jobs = [j for j in description if is_valid_job(j)]
                                        job_index = valid_jobs.index(job) + 1
                                        job_info['å·¥ä½œç·¨è™Ÿ'] = f"å·¥ä½œ {job_index}"
                                    else:
                                        job_info['å·¥ä½œç·¨è™Ÿ'] = ""
                                    all_jobs.append(job_info)
            elif multi_file_keys:
                # å¤šæª”æ¡ˆæƒ…æ³
                multi_file_keys.sort(key=lambda x: x.split('_file')[-1])
                
                for file_key in multi_file_keys:
                    # è§£ææª”æ¡ˆç·¨è™Ÿå’Œå¯èƒ½çš„é ç¢¼
                    key_parts = file_key.replace(f"{process_id}_", "").split('_')
                    if 'page' in file_key:
                        # å¤šæª”æ¡ˆPDFçš„æƒ…æ³
                        file_part = key_parts[0]  # file01
                        page_part = key_parts[1]  # page1
                        page_num = page_part.replace('page', '')
                        file_display = f"{file_part}_page{page_num}"
                    else:
                        # å¤šæª”æ¡ˆåœ–ç‰‡çš„æƒ…æ³
                        file_display = key_parts[0]
                        page_num = file_display
                    
                    for filename, image_data in image_storage._storage[file_key].items():
                        # è·³éåµéŒ¯åœ–åƒ
                        if any(debug_type in filename for debug_type in ['_original', '_mask_', '_final_combined']):
                            continue
                        
                        # ç›´æ¥å¾ image_storage ç²å–æè¿°
                        description = []
                        if file_key in image_storage._storage and \
                           filename in image_storage._storage[file_key] and \
                           'description' in image_storage._storage[file_key][filename]:
                            description = image_storage._storage[file_key][filename]['description']
                        else:
                            print(f"è­¦å‘Š: åœ¨ send_to_spreadsheet ä¸­æ‰¾ä¸åˆ°åœ–ç‰‡ {filename} (file_key: {file_key}) çš„æè¿°ï¼Œå°‡ä½¿ç”¨ç©ºæè¿°ã€‚")
                            description = [{
                                "å·¥ä½œ": "æè¿°æœªæ‰¾åˆ°",
                                "è¡Œæ¥­": "", "æ™‚é–“": "", "è–ªè³‡": "",
                                "åœ°é»": "", "è¯çµ¡æ–¹å¼": "", "å…¶ä»–": ""
                            }]
                        
                        # æ”¶é›†æœ‰æ•ˆçš„å·¥ä½œè³‡è¨Š
                        if isinstance(description, list):
                            for i, job in enumerate(description):
                                if is_valid_job(job):
                                    job_info = job.copy()
                                    job_info['ä¾†æºåœ–ç‰‡'] = filename
                                    job_info['é ç¢¼'] = page_num
                                    job_info['åœ–ç‰‡ç·¨è™Ÿ'] = f"{file_display}_{filename.split('.')[0]}"
                                    if len([j for j in description if is_valid_job(j)]) > 1:
                                        valid_jobs = [j for j in description if is_valid_job(j)]
                                        job_index = valid_jobs.index(job) + 1
                                        job_info['å·¥ä½œç·¨è™Ÿ'] = f"å·¥ä½œ {job_index}"
                                    else:
                                        job_info['å·¥ä½œç·¨è™Ÿ'] = ""
                                    all_jobs.append(job_info)
            elif process_id in image_storage._storage:
                # å–®ä¸€åœ–åƒæƒ…æ³
                for filename, image_data in image_storage._storage[process_id].items():
                    # è·³éåµéŒ¯åœ–åƒ
                    if any(debug_type in filename for debug_type in ['_original', '_mask_', '_final_combined']):
                        continue
                    
                    # ç›´æ¥å¾ image_storage ç²å–æè¿°
                    description = []
                    if process_id in image_storage._storage and \
                       filename in image_storage._storage[process_id] and \
                       'description' in image_storage._storage[process_id][filename]:
                        description = image_storage._storage[process_id][filename]['description']
                    else:
                        print(f"è­¦å‘Š: åœ¨ send_to_spreadsheet ä¸­æ‰¾ä¸åˆ°åœ–ç‰‡ {filename} (process_id: {process_id}) çš„æè¿°ï¼Œå°‡ä½¿ç”¨ç©ºæè¿°ã€‚")
                        description = [{
                            "å·¥ä½œ": "æè¿°æœªæ‰¾åˆ°",
                            "è¡Œæ¥­": "", "æ™‚é–“": "", "è–ªè³‡": "",
                            "åœ°é»": "", "è¯çµ¡æ–¹å¼": "", "å…¶ä»–": ""
                        }]
                    
                    # æ”¶é›†æœ‰æ•ˆçš„å·¥ä½œè³‡è¨Š
                    if isinstance(description, list):
                        for i, job in enumerate(description):
                            if is_valid_job(job):
                                job_info = job.copy()
                                job_info['ä¾†æºåœ–ç‰‡'] = filename
                                job_info['é ç¢¼'] = '1'
                                job_info['åœ–ç‰‡ç·¨è™Ÿ'] = filename.split('.')[0]
                                if len([j for j in description if is_valid_job(j)]) > 1:
                                    valid_jobs = [j for j in description if is_valid_job(j)]
                                    job_index = valid_jobs.index(job) + 1
                                    job_info['å·¥ä½œç·¨è™Ÿ'] = f"å·¥ä½œ {job_index}"
                                else:
                                    job_info['å·¥ä½œç·¨è™Ÿ'] = ""
                                all_jobs.append(job_info)
            else:
                return jsonify({'error': 'è™•ç†çµæœä¸å­˜åœ¨'}), 404
            
            if not all_jobs:
                return jsonify({'error': 'æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è·ç¼ºè³‡æ–™'}), 404
            
            # æº–å‚™ç™¼é€åˆ° Google Apps Script çš„è³‡æ–™
            payload = {
                'action': 'addJobs',
                'jobs': all_jobs,
                'metadata': {
                    'process_id': process_id,
                    'total_jobs': len(all_jobs),
                    'timestamp': datetime.now().isoformat(),
                    'source': 'newspaper_job_extractor'
                }
            }
            
            # æ·»åŠ è©³ç´°æ—¥èªŒè¨˜éŒ„
            print(f"æº–å‚™ç™¼é€è³‡æ–™åˆ° Google Apps Script: {apps_script_url}")
            print(f"è·ç¼ºè³‡æ–™æ•¸é‡: {len(all_jobs)}")
            print(f"ç¬¬ä¸€ç­†è·ç¼ºè³‡æ–™ç¯„ä¾‹: {all_jobs[0] if all_jobs else 'None'}")
            print(f"Payload å¤§å°: {len(str(payload))} å­—ç¬¦")
            
            # ç™¼é€è³‡æ–™åˆ° Google Apps Script
            headers = {
                'Content-Type': 'application/json'
            }
            
            try:
                response = requests.post(apps_script_url, json=payload, headers=headers, timeout=Config.REQUEST_TIMEOUT)
                print(f"HTTP å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
                print(f"HTTP å›æ‡‰å…§å®¹: {response.text[:500]}...")  # åªé¡¯ç¤ºå‰500å­—ç¬¦
            except Exception as e:
                print(f"ç™¼é€è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                raise
            
            if response.status_code == 200:
                result = response.json() if response.content else {}
                return jsonify({
                    'success': True,
                    'message': f'æˆåŠŸç™¼é€ {len(all_jobs)} ç­†è·ç¼ºè³‡æ–™åˆ° Google Sheets',
                    'jobs_sent': len(all_jobs),
                    'spreadsheet_url': result.get('spreadsheet_url', ''),
                    'spreadsheet_id': result.get('spreadsheet_id', ''),
                    'response': result
                }), 200
            else:
                return jsonify({
                    'error': f'ç™¼é€å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}',
                    'response_text': response.text
                }), response.status_code
                
        except requests.exceptions.Timeout:
            return jsonify({'error': 'è«‹æ±‚è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ Google Apps Script URL æ˜¯å¦æ­£ç¢º'}), 408
        except requests.exceptions.RequestException as e:
            return jsonify({'error': f'ç¶²è·¯è«‹æ±‚éŒ¯èª¤: {str(e)}'}), 500
        except Exception as e:
            return jsonify({'error': f'ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500
    
    return app, socketio

def cleanup_memory_storage(process_id):
    """æ¸…ç†è¨˜æ†¶é«”ä¸­çš„éæœŸè³‡æ–™"""
    # æ¸…ç†æ‰€æœ‰ç›¸é—œçš„process_idè¨˜éŒ„
    image_storage.remove_process(process_id)
    job_storage.remove_process(process_id)
    progress_tracker.remove_progress(process_id)
    print(f"æ¸…ç†è¨˜æ†¶é«”è³‡æ–™: {process_id}")

def start_cleanup_scheduler():
    """å•Ÿå‹•å®šæ™‚æ¸…ç†ä»»å‹™"""
    def run_scheduled_cleanup():
        print("åŸ·è¡Œå®šæ™‚æ¸…ç†ä»»å‹™...")
        cleanup_old_files(Config.UPLOAD_FOLDER, Config.RESULTS_FOLDER, Config.CLEANUP_MAX_AGE_HOURS)
    
    # è¨­ç½®æ¯4å°æ™‚åŸ·è¡Œä¸€æ¬¡æ¸…ç†
    schedule.every(Config.CLEANUP_INTERVAL_HOURS).hours.do(run_scheduled_cleanup)
    
    # åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­é‹è¡Œæ’ç¨‹å™¨
    def schedule_runner():
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
    
    cleanup_thread = threading.Thread(target=schedule_runner, daemon=True)
    cleanup_thread.start()
    print(f"å®šæ™‚æ¸…ç†ä»»å‹™å·²å•Ÿå‹•ï¼Œæ¯{Config.CLEANUP_INTERVAL_HOURS}å°æ™‚åŸ·è¡Œä¸€æ¬¡")

# å‰µå»ºæ‡‰ç”¨å¯¦ä¾‹
app, socketio = create_app()

if __name__ == '__main__':
    # å•Ÿå‹•å®šæ™‚æ¸…ç†ä»»å‹™
    start_cleanup_scheduler()
    
    # ç«‹å³åŸ·è¡Œä¸€æ¬¡æ¸…ç†ï¼ˆæ¸…ç†å•Ÿå‹•æ™‚çš„èˆŠæª”æ¡ˆï¼‰
    cleanup_old_files(Config.UPLOAD_FOLDER, Config.RESULTS_FOLDER, Config.CLEANUP_MAX_AGE_HOURS)
    
    # å¾é…ç½®è®€å–ä¼ºæœå™¨è¨­å®š
    host = Config.FLASK_HOST
    port = Config.FLASK_PORT
    debug = Config.FLASK_DEBUG
    
    print(f"ğŸš€ å•Ÿå‹•å ±ç´™å·¥ä½œå»£å‘Šæå–ç³»çµ±...")
    print(f"ğŸ“¡ ä¼ºæœå™¨åœ°å€: http://{host}:{port}")
    print(f"ğŸ”§ é™¤éŒ¯æ¨¡å¼: {debug}")
    print(f"ğŸ§¹ è‡ªå‹•æ¸…ç†: æ¯{Config.CLEANUP_INTERVAL_HOURS}å°æ™‚åŸ·è¡Œ")
    
    socketio.run(app, debug=debug, host=host, port=port) 